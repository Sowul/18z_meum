{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metody ewolucyjne i uczenie się maszyn\n",
    "## Na kilku zadaniach klasyfikacji z repozytorium UCI porównać metody xgboost i catboost\n",
    "### Agnieszka Czaplicka, Bartosz Sowul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test: instalacja potrzebnych modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.12.1.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from catboost) (1.13.3)\n",
      "Requirement already satisfied: enum34 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from catboost) (1.1.6)\n",
      "Requirement already satisfied: six in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from catboost) (1.11.0)\n",
      "Requirement already satisfied: pandas>=0.19.1 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: pytz>=2011k in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas>=0.19.1->catboost) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas>=0.19.1->catboost) (2.7.5)\n",
      "Requirement already satisfied: xgboost in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.81)\n",
      "Requirement already satisfied: numpy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from xgboost) (1.13.3)\n",
      "Requirement already satisfied: scipy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from xgboost) (1.2.0)\n",
      "Requirement already satisfied: matplotlib in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (2.0.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pytz in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (2018.9)\n",
      "Requirement already satisfied: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (2.7.5)\n",
      "Requirement already satisfied: six>=1.10 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (1.13.3)\n",
      "Requirement already satisfied: pandas in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas) (1.13.3)\n",
      "Requirement already satisfied: six>=1.5 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from python-dateutil>=2->pandas) (1.11.0)\n",
      "Requirement already satisfied: numpy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (1.13.3)\n",
      "Requirement already satisfied: scikit_learn in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.19.1)\n",
      "Collecting xlrd\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/16/63576a1a001752e34bf8ea62e367997530dc553b689356b9879339cf45a4/xlrd-1.2.0-py2.py3-none-any.whl (103kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 1.1MB/s \n",
      "\u001b[?25hInstalling collected packages: xlrd\n",
      "Successfully installed xlrd-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "!pip install xgboost\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit_learn\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ładowanie potrzebnych modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-pVhOfzLx9us"
   },
   "source": [
    "## Funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie zbiorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Adult\")\\nX, y = prepare(\\'./data/adult/adult.data.txt\\')\\nprint(\"\\n------------------------------------------------\\n\\nAnnealing\")\\nX2, y2 = prepare(\\'./data/annealing/anneal.data.txt\\')\\nX2 = X2[:, np.concatenate((np.arange(5), [8, 26, 27, 28, 29, 31]), axis=None)]\\nprint(\"\\n------------------------------------------------\\n\\nBreast\")\\nX3, y3 = prepare(\\'./data/breast/breast-cancer-wisconsin.data.txt\\')\\nX3 = X3[:, 1:]\\nprint(\"\\n------------------------------------------------\\n\\nCTG\")\\nX4, y4 = prepare(\\'./data/cardiotocography/CTG.xls\\')\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zbiory Adult/Annealing/Breast/CTG\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "\n",
    "def prepare(filename):\n",
    "    if filename[-7:] == 'CTG.xls':\n",
    "        df = pd.read_excel(filename, sheet_name='Data', header=None, usecols='K:AE,AT', skiprows=2, nrows=2126)\n",
    "    else:\n",
    "        df = pd.read_csv(filename, header=None)\n",
    "    \n",
    "    if filename[-32:] == 'breast-cancer-wisconsin.data.txt':\n",
    "        df[6] = df[6].replace('?', 0)\n",
    "        df[6] = df[6].astype('int', errors='ignore')\n",
    "        df[6] = df[6].replace(0, np.median(df[6]))\n",
    "    #print(df.dtypes)\n",
    "\n",
    "    array = df.values\n",
    "    X = array[:, 0:df.shape[1]-1]\n",
    "    print('Przetwarzanie wstępne...')\n",
    "    for i in range(np.shape(X)[1]):\n",
    "        if df[i].dtype == object:\n",
    "            names_in_col = df[i].unique()\n",
    "            names_in_col = sorted(names_in_col, key=lambda v: (v.lower(), v))\n",
    "            if names_in_col[0].strip() == '?':\n",
    "                names_in_col = names_in_col[1:]\n",
    "            elif names_in_col[len(names_in_col) - 1].strip() == '?':\n",
    "                names_in_col = names_in_col[:-1]\n",
    "            #print(names_in_col)\n",
    "            col_dict = dict(zip(names_in_col, range(1, len(names_in_col)+1)))\n",
    "            X[:, i] = np.array([col_dict.get(elem, np.NaN) for elem in df[i]])\n",
    "        else:\n",
    "            df[i] = df[i].replace('?', np.NaN)\n",
    "            # df[i] = df[i].fillna(value=0)\n",
    "            X[:, i] = np.array(df[i])\n",
    "\n",
    "    if df[df.shape[1]-1].dtype == object:\n",
    "        names_in_col = df[df.shape[1]-1].unique()\n",
    "        names_in_col = sorted(names_in_col, key=lambda v: (v.lower(), v))\n",
    "        #print(names_in_col)\n",
    "        col_dict = dict(zip(names_in_col, range(len(names_in_col))))\n",
    "        y = np.array([col_dict.get(elem) for elem in df[df.shape[1]-1]])\n",
    "    else:\n",
    "        y = array[:, df.shape[1]-1]\n",
    "\n",
    "    imputer = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "    X = imputer.fit_transform(X)\n",
    "    # scaler = MinMaxScaler(feature_range=(0, 1)) # skalowanie przy walidacji\n",
    "    # X = scaler.fit_transform(X)\n",
    "    print('Przetworzono.')\n",
    "    return X, y\n",
    "\n",
    "'''\n",
    "print(\"Adult\")\n",
    "X, y = prepare('./data/adult/adult.data.txt')\n",
    "print(\"\\n------------------------------------------------\\n\\nAnnealing\")\n",
    "X2, y2 = prepare('./data/annealing/anneal.data.txt')\n",
    "X2 = X2[:, np.concatenate((np.arange(5), [8, 26, 27, 28, 29, 31]), axis=None)]\n",
    "print(\"\\n------------------------------------------------\\n\\nBreast\")\n",
    "X3, y3 = prepare('./data/breast/breast-cancer-wisconsin.data.txt')\n",
    "X3 = X3[:, 1:]\n",
    "print(\"\\n------------------------------------------------\\n\\nCTG\")\n",
    "X4, y4 = prepare('./data/cardiotocography/CTG.xls')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-krotna walidacja krzyżowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, K, clf):\n",
    "    n = np.shape(X)[0]\n",
    "    K_cv_ind = np.random.permutation(n)\n",
    "    for k in range(K):\n",
    "        print('\\nk = ', k)\n",
    "        ind_test = K_cv_ind[round(k * (1 / K) * n): round((k+1) * (1 / K) * n)]\n",
    "        #print('test:', ind_test)\n",
    "        X_test = X[ind_test, :]\n",
    "        y_test = y[ind_test]\n",
    "        if k != 0:\n",
    "            ind_train = K_cv_ind[np.concatenate((np.arange(round(k * (1 / K) * n)),\n",
    "                                                 np.arange(round((k+1) * (1 / K) * n), n)), axis=None)]\n",
    "            X_train = X[ind_train, :]\n",
    "            y_train = y[ind_train]\n",
    "        else:\n",
    "            ind_train = K_cv_ind[range(round((k+1) * (1 / K) * n), n)]\n",
    "            X_train = X[ind_train, :]\n",
    "            y_train = y[ind_train]\n",
    "        #print('train:', ind_train)\n",
    "\n",
    "        max_train = np.amax(X_train, axis=0)\n",
    "        min_train = np.amin(X_train, axis=0)\n",
    "        X_train = 2 * (X_train - min_train) / (max_train - min_train) - 1\n",
    "        X_test = 2 * (X_test - min_train) / (max_train - min_train) - 1\n",
    "\n",
    "        find_params(clf, X_train, y_train)\n",
    "        #params = find_params(clf, X_train, y_train)\n",
    "        #values = predict(X_test, y_test)\n",
    "        \n",
    "#cross_validation(X, y, 5, clf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optymalizacja hiperparametrów przy użyciu RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcje pomocnicze do raportowania i zapisu wyników eksperymentów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "def save_results(results, filename='results.csv'):\n",
    "    mode = 'w'\n",
    "    path = Path(filename)\n",
    "    if path.is_file():\n",
    "         mode = 'a'\n",
    "    with open(filename, mode) as f:\n",
    "        w = csv.writer(f)\n",
    "        if mode == 'w':\n",
    "            w.writerow(results[0].keys())\n",
    "        else:\n",
    "            pass\n",
    "        for result in results:\n",
    "            w.writerow(result.values())\n",
    "\n",
    "def report(optimizer, algo, scoring, seed, dataset, n_top=3):\n",
    "    print('BEST')\n",
    "    print(f\"Mean validation score: {optimizer.cv_results_['mean_test_'+scoring[-1]][optimizer.best_index_]:.3f} \\\n",
    "          (std: {optimizer.cv_results_['std_test_'+scoring[-1]][optimizer.best_index_]:.3f})\")\n",
    "    print(f'Params: {optimizer.best_params_}')\n",
    "    print()\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for metric in scoring:\n",
    "        print(f'Najlepsze hiperparametry ze względu na metrykę {metric}:')\n",
    "        cv_results = [tup[0] for tup in sorted(enumerate(optimizer.cv_results_['mean_test_'+metric]), key=lambda x:x[1])]\n",
    "        for idx in cv_results[::-1][:3]:\n",
    "            results.append({'dataset': dataset, 'seed': seed, 'algo': type(algo).__name__,\n",
    "                            'metric': metric, 'model_id': idx,\n",
    "                            'mean_test_': optimizer.cv_results_['mean_test_'+metric][idx],\n",
    "                            'std_test_': optimizer.cv_results_['std_test_'+metric][idx],\n",
    "                            'params': optimizer.cv_results_['params'][idx]})\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                      optimizer.cv_results_['mean_test_'+metric][idx],\n",
    "                      optimizer.cv_results_['std_test_'+metric][idx]))\n",
    "            print(\"Params: {0}\".format(optimizer.cv_results_['params'][idx]))\n",
    "            print()\n",
    "    else:\n",
    "        save_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy, F1 score i logloss\n",
    "from time import time\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "import scipy.stats as st\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def find_params(clf, scoring, seed, X=None, y=None):\n",
    "    params = None\n",
    "    if type(clf) == XGBClassifier:\n",
    "        print(f'Optymalizacja hiperparametrów {type(clf).__name__}...')\n",
    "#learning_rate\n",
    "#gamma\n",
    "#max_depth\n",
    "#min_child_weight\n",
    "#subsample\n",
    "#colsample_bytree\n",
    "#reg_alpha\n",
    "#reg_lambda\n",
    "#n_estimators\n",
    "        params = {\n",
    "            'learning_rate': st.uniform(0.05, 1.0),\n",
    "            'gamma': st.uniform(0, 10),\n",
    "            'max_depth': st.randint(3, 17),\n",
    "            'min_child_weight': st.expon(0, 50),\n",
    "            'subsample': st.beta(10, 1),\n",
    "            'colsample_bytree': st.beta(10, 1) ,\n",
    "            'reg_alpha': st.expon(0, 50),\n",
    "            'reg_lambda': st.randint(0, 100),\n",
    "            'n_estimators': st.randint(3, 50),\n",
    "        }\n",
    "    elif type(clf) == CatBoostClassifier:\n",
    "#learning_rate\n",
    "#depth\n",
    "#l2_leaf_reg\n",
    "#rsm\n",
    "#random_strength\n",
    "#iterations\n",
    "        print(f'Optymalizacja hiperparametrów {type(clf).__name__}...')\n",
    "        params = {\n",
    "            'learning_rate': st.uniform(0.05, 1.0),\n",
    "            'depth': st.randint(3, 17),\n",
    "            'l2_leaf_reg': st.randint(0, 100),\n",
    "            'rsm': st.uniform(0.0, 1.0),\n",
    "            'random_strength': st.uniform(0.05, 10),\n",
    "            'iterations': st.randint(3, 50),\n",
    "        }\n",
    "    else:\n",
    "        print(f'Błąd: {type(clf)} klasyfikator nie jest obsługiwany.')\n",
    "    \n",
    "    # run randomized search\n",
    "    n_iter_search = 10\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=params,\n",
    "                                       n_iter=n_iter_search, cv=5, scoring=scoring,\n",
    "                                       refit='neg_log_loss', return_train_score=True, random_state=seed)\n",
    "\n",
    "    start = time()\n",
    "    random_search.fit(X, y)\n",
    "    print(f'\\nRandomizedSearchCV trwało {time() - start:.2f} sekund dla {n_iter_search} kandydatów.')\n",
    "    return random_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testy na zbiorze Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbiór Adult\n",
      "Przetwarzanie wstępne...\n",
      "Przetworzono.\n",
      "Optymalizacja hiperparametrów XGBClassifier...\n",
      "\n",
      "RandomizedSearchCV trwało 58.39 sekund dla 10 kandydatów.\n",
      "BEST\n",
      "Mean validation score: -0.293           (std: 0.006)\n",
      "Params: {'colsample_bytree': 0.86900124541044066, 'gamma': 2.1049924581368176, 'learning_rate': 0.85206457718643547, 'max_depth': 3, 'min_child_weight': 8.1923283466419132, 'n_estimators': 39, 'reg_alpha': 11.619779341850629, 'reg_lambda': 20, 'subsample': 0.9003944179579163}\n",
      "\n",
      "Najlepsze hiperparametry ze względu na metrykę accuracy:\n",
      "Mean validation score: 0.867 (std: 0.006)\n",
      "Params: {'colsample_bytree': 0.86900124541044066, 'gamma': 2.1049924581368176, 'learning_rate': 0.85206457718643547, 'max_depth': 3, 'min_child_weight': 8.1923283466419132, 'n_estimators': 39, 'reg_alpha': 11.619779341850629, 'reg_lambda': 20, 'subsample': 0.9003944179579163}\n",
      "\n",
      "Mean validation score: 0.865 (std: 0.004)\n",
      "Params: {'colsample_bytree': 0.96822823759893117, 'gamma': 3.6077620064287794, 'learning_rate': 0.8997204066587916, 'max_depth': 11, 'min_child_weight': 19.197911834329673, 'n_estimators': 30, 'reg_alpha': 1.9464979068715309, 'reg_lambda': 13, 'subsample': 0.8665556736882436}\n",
      "\n",
      "Mean validation score: 0.859 (std: 0.003)\n",
      "Params: {'colsample_bytree': 0.86861133982662841, 'gamma': 2.1609865570439748, 'learning_rate': 0.1600379726637749, 'max_depth': 9, 'min_child_weight': 9.7673407588582783, 'n_estimators': 19, 'reg_alpha': 32.89757176103668, 'reg_lambda': 86, 'subsample': 0.9701258944997091}\n",
      "\n",
      "Najlepsze hiperparametry ze względu na metrykę f1:\n",
      "Mean validation score: 0.698 (std: 0.007)\n",
      "Params: {'colsample_bytree': 0.96822823759893117, 'gamma': 3.6077620064287794, 'learning_rate': 0.8997204066587916, 'max_depth': 11, 'min_child_weight': 19.197911834329673, 'n_estimators': 30, 'reg_alpha': 1.9464979068715309, 'reg_lambda': 13, 'subsample': 0.8665556736882436}\n",
      "\n",
      "Mean validation score: 0.697 (std: 0.014)\n",
      "Params: {'colsample_bytree': 0.86900124541044066, 'gamma': 2.1049924581368176, 'learning_rate': 0.85206457718643547, 'max_depth': 3, 'min_child_weight': 8.1923283466419132, 'n_estimators': 39, 'reg_alpha': 11.619779341850629, 'reg_lambda': 20, 'subsample': 0.9003944179579163}\n",
      "\n",
      "Mean validation score: 0.676 (std: 0.011)\n",
      "Params: {'colsample_bytree': 0.9468356101664871, 'gamma': 0.27447959813153733, 'learning_rate': 0.50413664315846995, 'max_depth': 10, 'min_child_weight': 102.05951505901587, 'n_estimators': 42, 'reg_alpha': 17.834663182518256, 'reg_lambda': 92, 'subsample': 0.61018859658869928}\n",
      "\n",
      "Najlepsze hiperparametry ze względu na metrykę neg_log_loss:\n",
      "Mean validation score: -0.293 (std: 0.006)\n",
      "Params: {'colsample_bytree': 0.86900124541044066, 'gamma': 2.1049924581368176, 'learning_rate': 0.85206457718643547, 'max_depth': 3, 'min_child_weight': 8.1923283466419132, 'n_estimators': 39, 'reg_alpha': 11.619779341850629, 'reg_lambda': 20, 'subsample': 0.9003944179579163}\n",
      "\n",
      "Mean validation score: -0.296 (std: 0.005)\n",
      "Params: {'colsample_bytree': 0.96822823759893117, 'gamma': 3.6077620064287794, 'learning_rate': 0.8997204066587916, 'max_depth': 11, 'min_child_weight': 19.197911834329673, 'n_estimators': 30, 'reg_alpha': 1.9464979068715309, 'reg_lambda': 13, 'subsample': 0.8665556736882436}\n",
      "\n",
      "Mean validation score: -0.311 (std: 0.005)\n",
      "Params: {'colsample_bytree': 0.9468356101664871, 'gamma': 0.27447959813153733, 'learning_rate': 0.50413664315846995, 'max_depth': 10, 'min_child_weight': 102.05951505901587, 'n_estimators': 42, 'reg_alpha': 17.834663182518256, 'reg_lambda': 92, 'subsample': 0.61018859658869928}\n",
      "\n",
      "Optymalizacja hiperparametrów CatBoostClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV trwało 357.91 sekund dla 10 kandydatów.\n",
      "BEST\n",
      "Mean validation score: -0.291           (std: 0.004)\n",
      "Params: {'depth': 5, 'iterations': 46, 'l2_leaf_reg': 86, 'learning_rate': 0.84396256047962848, 'random_strength': 8.4556964872428129, 'rsm': 0.81520745745294065}\n",
      "\n",
      "Najlepsze hiperparametry ze względu na metrykę accuracy:\n",
      "Mean validation score: 0.867 (std: 0.003)\n",
      "Params: {'depth': 5, 'iterations': 46, 'l2_leaf_reg': 86, 'learning_rate': 0.84396256047962848, 'random_strength': 8.4556964872428129, 'rsm': 0.81520745745294065}\n",
      "\n",
      "Mean validation score: 0.865 (std: 0.004)\n",
      "Params: {'depth': 6, 'iterations': 36, 'l2_leaf_reg': 38, 'learning_rate': 0.89380186955457119, 'random_strength': 7.3120188758759106, 'rsm': 0.27030569335406984}\n",
      "\n",
      "Mean validation score: 0.858 (std: 0.004)\n",
      "Params: {'depth': 7, 'iterations': 47, 'l2_leaf_reg': 84, 'learning_rate': 0.35178945091410735, 'random_strength': 8.5890645838724424, 'rsm': 0.29771597903464209}\n",
      "\n",
      "Najlepsze hiperparametry ze względu na metrykę f1:\n",
      "Mean validation score: 0.698 (std: 0.008)\n",
      "Params: {'depth': 5, 'iterations': 46, 'l2_leaf_reg': 86, 'learning_rate': 0.84396256047962848, 'random_strength': 8.4556964872428129, 'rsm': 0.81520745745294065}\n",
      "\n",
      "Mean validation score: 0.693 (std: 0.010)\n",
      "Params: {'depth': 6, 'iterations': 36, 'l2_leaf_reg': 38, 'learning_rate': 0.89380186955457119, 'random_strength': 7.3120188758759106, 'rsm': 0.27030569335406984}\n",
      "\n",
      "Mean validation score: 0.673 (std: 0.012)\n",
      "Params: {'depth': 9, 'iterations': 15, 'l2_leaf_reg': 45, 'learning_rate': 0.77029827882514457, 'random_strength': 3.8606000511622236, 'rsm': 0.62423656935958238}\n",
      "\n",
      "Najlepsze hiperparametry ze względu na metrykę neg_log_loss:\n",
      "Mean validation score: -0.291 (std: 0.004)\n",
      "Params: {'depth': 5, 'iterations': 46, 'l2_leaf_reg': 86, 'learning_rate': 0.84396256047962848, 'random_strength': 8.4556964872428129, 'rsm': 0.81520745745294065}\n",
      "\n",
      "Mean validation score: -0.295 (std: 0.004)\n",
      "Params: {'depth': 6, 'iterations': 36, 'l2_leaf_reg': 38, 'learning_rate': 0.89380186955457119, 'random_strength': 7.3120188758759106, 'rsm': 0.27030569335406984}\n",
      "\n",
      "Mean validation score: -0.303 (std: 0.004)\n",
      "Params: {'depth': 7, 'iterations': 47, 'l2_leaf_reg': 84, 'learning_rate': 0.35178945091410735, 'random_strength': 8.5890645838724424, 'rsm': 0.29771597903464209}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Zbiór Adult\")\n",
    "\n",
    "scoring = ['accuracy', 'f1', 'neg_log_loss']\n",
    "seeds = [111]\n",
    "\n",
    "dataset = 'Adult'\n",
    "X, y = prepare('./data/adult/adult.data.txt')\n",
    "\n",
    "for seed in seeds:\n",
    "    xgb = XGBClassifier()\n",
    "    ctb = CatBoostClassifier(loss_function='MultiClass', verbose=False)\n",
    "    \n",
    "    optimizer_xgb1 = find_params(xgb, scoring, seed, X, y)\n",
    "    report(optimizer_xgb1, xgb, scoring, seed, dataset)\n",
    "\n",
    "    optimizer_ctb1 = find_params(ctb, scoring, seed, X, y)\n",
    "    report(optimizer_ctb1, ctb, scoring, seed, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testy na zbiorze Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbiór Annealing\n",
      "Przetwarzanie wstępne...\n",
      "Przetworzono.\n"
     ]
    }
   ],
   "source": [
    "print(\"Zbiór Annealing\")\n",
    "\n",
    "scoring = ['accuracy', 'f1', 'neg_log_loss']\n",
    "seeds = [111]\n",
    "\n",
    "dataset = 'Annealing'\n",
    "X, y = prepare('./data/annealing/anneal.data.txt')\n",
    "\n",
    "for seed in seeds:\n",
    "    xgb = XGBClassifier()\n",
    "    ctb = CatBoostClassifier(loss_function='MultiClass', verbose=False)\n",
    "    \n",
    "    optimizer_xgb2 = find_params(xgb, scoring, seed, X, y)\n",
    "    report(optimizer_xgb2, xgb, scoring, seed, dataset)\n",
    "\n",
    "    optimizer_ctb2 = find_params(ctb, scoring, seed, X, y)\n",
    "    report(optimizer_ctb2, ctb, scoring, seed, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testy na zbiorze Breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbiór Breast\n",
      "Przetwarzanie wstępne...\n",
      "Przetworzono.\n"
     ]
    }
   ],
   "source": [
    "print(\"Zbiór Breast\")\n",
    "\n",
    "scoring = ['accuracy', 'f1', 'neg_log_loss']\n",
    "seeds = [111]\n",
    "\n",
    "dataset = 'Breast'\n",
    "X, y = prepare('./data/breast/breast-cancer-wisconsin.data.txt')\n",
    "\n",
    "for seed in seeds:\n",
    "    xgb = XGBClassifier()\n",
    "    ctb = CatBoostClassifier(loss_function='MultiClass', verbose=False)\n",
    "    \n",
    "    optimizer_xgb3 = find_params(xgb, scoring, seed, X, y)\n",
    "    report(optimizer_xgb3, xgb, scoring, seed, dataset)\n",
    "\n",
    "    optimizer_ctb3 = find_params(ctb, scoring, seed, X, y)\n",
    "    report(optimizer_ctb3, ctb, scoring, seed, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testy na zbiorze CTG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbiór CTG\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xlrd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3abc3a3d5eb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Zbiór CTG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/cardiotocography/CTG.xls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-5eafeb658770>\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'CTG.xls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'K:AE,AT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2126\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheetname, header, skiprows, skip_footer, index_col, names, parse_cols, parse_dates, date_parser, na_values, thousands, convert_float, has_index_names, converters, dtype, true_values, false_values, engine, squeeze, **kwds)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     return io._parse_excel(\n",
      "\u001b[0;32m/media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, **kwds)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mxlrd\u001b[0m  \u001b[0;31m# throw an ImportError if we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__VERSION__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xlrd'"
     ]
    }
   ],
   "source": [
    "print(\"Zbiór CTG\")\n",
    "\n",
    "scoring = ['accuracy', 'f1', 'neg_log_loss']\n",
    "seeds = [111]\n",
    "\n",
    "dataset = 'Breast'\n",
    "X, y = prepare('./data/cardiotocography/CTG.xls')\n",
    "\n",
    "for seed in seeds:\n",
    "    xgb = XGBClassifier()\n",
    "    ctb = CatBoostClassifier(loss_function='MultiClass', verbose=False)\n",
    "    \n",
    "    optimizer_xgb4 = find_params(xgb, scoring, seed, X, y)\n",
    "    report(optimizer_xgb4, xgb, scoring, seed, dataset)\n",
    "\n",
    "    optimizer_ctb4 = find_params(ctb, scoring, seed, X, y)\n",
    "    report(optimizer_ctb4, ctb, scoring, seed, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8QAWNjizy_3O"
   },
   "source": [
    "## Open In Colab Badge\n",
    "\n",
    "Anybody can open a copy of any github-hosted notebook within Colab. To make it easier to give people access to live views of GitHub-hosted notebooks,\n",
    "colab provides a [shields.io](http://shields.io/)-style badge, which appears as follows:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
    "\n",
    "The markdown for the above badge is the following:\n",
    "\n",
    "```markdown\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
    "```\n",
    "\n",
    "The HTML equivalent is:\n",
    "\n",
    "```HTML\n",
    "<a href=\"https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "```\n",
    "\n",
    "Remember to replace the notebook URL in this template with the notebook you want to link to."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colab-github-demo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
