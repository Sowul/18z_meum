{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metody ewolucyjne i uczenie się maszyn\n",
    "## Na kilku zadaniach klasyfikacji z repozytorium UCI porównać metody xgboost i catboost\n",
    "### Agnieszka Czaplicka, Bartosz Sowul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test: instalacja potrzebnych modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.12.1.1)\n",
      "Requirement already satisfied: six in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from catboost) (1.11.0)\n",
      "Requirement already satisfied: pandas>=0.19.1 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from catboost) (1.13.3)\n",
      "Requirement already satisfied: enum34 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from catboost) (1.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas>=0.19.1->catboost) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas>=0.19.1->catboost) (2018.9)\n",
      "Requirement already satisfied: xgboost in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.81)\n",
      "Requirement already satisfied: scipy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from xgboost) (1.2.0)\n",
      "Requirement already satisfied: numpy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from xgboost) (1.13.3)\n",
      "Requirement already satisfied: matplotlib in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (1.13.3)\n",
      "Requirement already satisfied: six>=1.10 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (2.7.5)\n",
      "Requirement already satisfied: pytz in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (2018.9)\n",
      "Requirement already satisfied: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (2.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pandas in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas) (1.13.3)\n",
      "Requirement already satisfied: six>=1.5 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from python-dateutil>=2->pandas) (1.11.0)\n",
      "Requirement already satisfied: numpy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (1.13.3)\n",
      "Requirement already satisfied: scikit_learn in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.19.1)\n",
      "Requirement already satisfied: hyperopt in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.1.1)\n",
      "Requirement already satisfied: six in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from hyperopt) (1.11.0)\n",
      "Requirement already satisfied: numpy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from hyperopt) (1.13.3)\n",
      "Requirement already satisfied: future in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from hyperopt) (0.17.1)\n",
      "Requirement already satisfied: scipy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from hyperopt) (1.2.0)\n",
      "Requirement already satisfied: networkx in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from hyperopt) (2.2)\n",
      "Requirement already satisfied: pymongo in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from hyperopt) (3.7.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from networkx->hyperopt) (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "!pip install xgboost\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit_learn\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ładowanie potrzebnych modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-pVhOfzLx9us"
   },
   "source": [
    "## Ładowanie i przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44444444,  0.        ,  0.        ,  0.        ,  0.11111111,\n",
       "         0.1       ,  0.22222222,  0.        ,  0.        ],\n",
       "       [ 0.44444444,  0.33333333,  0.33333333,  0.44444444,  0.66666667,\n",
       "         1.        ,  0.22222222,  0.11111111,  0.        ],\n",
       "       [ 0.22222222,  0.        ,  0.        ,  0.        ,  0.11111111,\n",
       "         0.2       ,  0.22222222,  0.        ,  0.        ],\n",
       "       [ 0.55555556,  0.77777778,  0.77777778,  0.        ,  0.22222222,\n",
       "         0.4       ,  0.22222222,  0.66666667,  0.        ],\n",
       "       [ 0.33333333,  0.        ,  0.        ,  0.22222222,  0.11111111,\n",
       "         0.1       ,  0.22222222,  0.        ,  0.        ],\n",
       "       [ 0.77777778,  1.        ,  1.        ,  0.77777778,  0.66666667,\n",
       "         1.        ,  0.88888889,  0.66666667,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.11111111,\n",
       "         1.        ,  0.22222222,  0.        ,  0.        ],\n",
       "       [ 0.11111111,  0.        ,  0.11111111,  0.        ,  0.11111111,\n",
       "         0.1       ,  0.22222222,  0.        ,  0.        ],\n",
       "       [ 0.11111111,  0.        ,  0.        ,  0.        ,  0.11111111,\n",
       "         0.1       ,  0.        ,  0.        ,  0.44444444],\n",
       "       [ 0.33333333,  0.11111111,  0.        ,  0.        ,  0.11111111,\n",
       "         0.1       ,  0.11111111,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# przyklad na zbiorze breast\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "def prepare(filename):\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    df = df.replace('?', np.NaN)\n",
    "    df[[6]] = df[[6]].fillna(value=0)\n",
    "\n",
    "    array = df.values\n",
    "    X = array[:,1:10]\n",
    "    y = np.array([1 if elem == 2 else 0 for elem in df[10]])\n",
    "\n",
    "    imputer = Imputer()\n",
    "    X = imputer.fit_transform(X)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    return X, y\n",
    "\n",
    "X, y = prepare('./data/breast/breast-cancer-wisconsin.data.txt')\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult\n",
      "[' Federal-gov', ' Local-gov', ' Never-worked', ' Private', ' Self-emp-inc', ' Self-emp-not-inc', ' State-gov', ' Without-pay']\n",
      "[' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate', ' HS-grad', ' Masters', ' Preschool', ' Prof-school', ' Some-college']\n",
      "[' Divorced', ' Married-AF-spouse', ' Married-civ-spouse', ' Married-spouse-absent', ' Never-married', ' Separated', ' Widowed']\n",
      "[' Adm-clerical', ' Armed-Forces', ' Craft-repair', ' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners', ' Machine-op-inspct', ' Other-service', ' Priv-house-serv', ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support', ' Transport-moving']\n",
      "[' Husband', ' Not-in-family', ' Other-relative', ' Own-child', ' Unmarried', ' Wife']\n",
      "[' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White']\n",
      "[' Female', ' Male']\n",
      "[' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India', ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru', ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia']\n",
      "[' <=50K', ' >50K']\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Annealing\n",
      "['TN', 'ZS']\n",
      "['C']\n",
      "['A', 'K', 'M', 'R', 'S', 'V', 'W']\n",
      "['T']\n",
      "['A', 'S']\n",
      "['1', '2', '3', '5']\n",
      "['N']\n",
      "['P']\n",
      "['D', 'E', 'F', 'G']\n",
      "['1', '2']\n",
      "['Y']\n",
      "['Y']\n",
      "['Y']\n",
      "['B', 'M']\n",
      "['Y']\n",
      "[]\n",
      "['C']\n",
      "['P']\n",
      "['Y']\n",
      "[]\n",
      "['Y']\n",
      "['Y']\n",
      "[]\n",
      "['B', 'C', 'V']\n",
      "['Y']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['COIL', 'SHEET']\n",
      "['N', 'Y']\n",
      "['2', '3']\n",
      "['1', '2', '3', '5', 'U']\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Breast\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "CTG\n"
     ]
    }
   ],
   "source": [
    "# zbiory Adult/Annealing/Breast/CTG\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "\n",
    "\n",
    "def prepare(filename):\n",
    "    if filename[-7:] == 'CTG.xls':\n",
    "        df = pd.read_excel(filename, sheet_name='Data', header=None, usecols='K:AE,AT', skiprows=2, nrows=2126)\n",
    "    else:\n",
    "        df = pd.read_csv(filename, header=None)\n",
    "    \n",
    "    if filename[-32:] == 'breast-cancer-wisconsin.data.txt':\n",
    "        df[6] = df[6].replace('?', 0)\n",
    "        df[6] = df[6].astype('int', errors='ignore')\n",
    "        df[6] = df[6].replace(0, np.median(df[6]))\n",
    "    #print(df.dtypes)\n",
    "\n",
    "    array = df.values\n",
    "    X = array[:, 0:df.shape[1]-1]\n",
    "\n",
    "    for i in range(np.shape(X)[1]):\n",
    "        if df[i].dtype == object:\n",
    "            names_in_col = df[i].unique()\n",
    "            names_in_col = sorted(names_in_col, key=lambda v: (v.lower(), v))\n",
    "            if names_in_col[0].strip() == '?':\n",
    "                names_in_col = names_in_col[1:]\n",
    "            elif names_in_col[len(names_in_col) - 1].strip() == '?':\n",
    "                names_in_col = names_in_col[:-1]\n",
    "            print(names_in_col)\n",
    "            col_dict = dict(zip(names_in_col, range(1, len(names_in_col)+1)))\n",
    "            X[:, i] = np.array([col_dict.get(elem, np.NaN) for elem in df[i]])\n",
    "        else:\n",
    "            df[i] = df[i].replace('?', np.NaN)\n",
    "            # df[i] = df[i].fillna(value=0)\n",
    "            X[:, i] = np.array(df[i])\n",
    "\n",
    "    if df[df.shape[1]-1].dtype == object:\n",
    "        names_in_col = df[df.shape[1]-1].unique()\n",
    "        names_in_col = sorted(names_in_col, key=lambda v: (v.lower(), v))\n",
    "        print(names_in_col)\n",
    "        col_dict = dict(zip(names_in_col, range(len(names_in_col))))\n",
    "        y = np.array([col_dict.get(elem) for elem in df[df.shape[1]-1]])\n",
    "    else:\n",
    "        y = array[:, df.shape[1]-1]\n",
    "\n",
    "    imputer = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "    X = imputer.fit_transform(X)\n",
    "    # scaler = MinMaxScaler(feature_range=(0, 1)) # skalowanie przy walidacji\n",
    "    # X = scaler.fit_transform(X)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "print(\"Adult\")\n",
    "X, y = prepare('./data/adult/adult.data.txt')\n",
    "print(\"\\n------------------------------------------------\\n\\nAnnealing\")\n",
    "X2, y2 = prepare('./data/annealing/anneal.data.txt')\n",
    "X2 = X2[:, np.concatenate((np.arange(5), [8, 26, 27, 28, 29, 31]), axis=None)]\n",
    "print(\"\\n------------------------------------------------\\n\\nBreast\")\n",
    "X3, y3 = prepare('./data/breast/breast-cancer-wisconsin.data.txt')\n",
    "X3 = X3[:, 1:]\n",
    "print(\"\\n------------------------------------------------\\n\\nCTG\")\n",
    "X4, y4 = prepare('./data/cardiotocography/CTG.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optymalizacja hiperparametrów przy użyciu RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (wykorzystano kod z dokumentacji scikit-learna, dostępny pod adresem https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration with suspicious time 3.26 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.15 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.47 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.17 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.47 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.47 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.29 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.21 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.26 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.2 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.33 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.19 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 1.89 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.47 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 1.2 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.32 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 3.55 sec ignored in overall statistics.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "\n",
      "Iteration with suspicious time 107 sec ignored in overall statistics.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "\n",
      "Iteration with suspicious time 8.3 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 6.74 sec ignored in overall statistics.\n",
      "\n",
      "Iteration with suspicious time 6.73 sec ignored in overall statistics.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 468.86 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.199 (std: 0.007)\n",
      "Parameters: {'depth': 11, 'iterations': 31, 'l2_leaf_reg': 14, 'learning_rate': 0.15403690664266384, 'random_strength': 5.329578051059891, 'rsm': 0.28181935600638564}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.198 (std: 0.006)\n",
      "Parameters: {'depth': 7, 'iterations': 47, 'l2_leaf_reg': 84, 'learning_rate': 0.35178945091410735, 'random_strength': 8.589064583872442, 'rsm': 0.2977159790346421}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.198 (std: 0.004)\n",
      "Parameters: {'depth': 6, 'iterations': 36, 'l2_leaf_reg': 38, 'learning_rate': 0.8938018695545712, 'random_strength': 7.312018875875911, 'rsm': 0.27030569335406984}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#accuracy, F1 score i logloss\n",
    "from time import time\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "import scipy.stats as st\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def find_params(clf, X=None, y=None):\n",
    "    # Utility function to report best scores\n",
    "    def report(results, n_top=3):\n",
    "        for i in range(1, n_top + 1):\n",
    "            candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "            for candidate in candidates:\n",
    "                print(\"Model with rank: {0}\".format(i))\n",
    "                print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                      results['mean_test_score'][candidate],\n",
    "                      results['std_test_score'][candidate]))\n",
    "                print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "                print(\"\")\n",
    "\n",
    "    params = None\n",
    "    if type(clf) == XGBClassifier:\n",
    "        print('ok')\n",
    "#learning_rate\n",
    "#gamma\n",
    "#max_depth\n",
    "#min_child_weight\n",
    "#subsample\n",
    "#colsample_bytree\n",
    "#reg_alpha\n",
    "#reg_lambda\n",
    "#n_estimators\n",
    "        params = {\n",
    "            'learning_rate': st.uniform(0.05, 1.0),\n",
    "            'gamma': st.uniform(0, 10),\n",
    "            'max_depth': st.randint(3, 17),\n",
    "            'min_child_weight': st.expon(0, 50),\n",
    "            'subsample': st.beta(10, 1),\n",
    "            'colsample_bytree': st.beta(10, 1) ,\n",
    "            'reg_alpha': st.expon(0, 50),\n",
    "            'reg_lambda': st.randint(0, 100),\n",
    "            'n_estimators': st.randint(3, 50),\n",
    "        }\n",
    "    elif type(clf) == CatBoostClassifier:\n",
    "#learning_rate\n",
    "#depth\n",
    "#l2_leaf_reg\n",
    "#rsm\n",
    "#random_strength\n",
    "#iterations\n",
    "        print('okok')\n",
    "        params = {\n",
    "            'learning_rate': st.uniform(0.05, 1.0),\n",
    "            'depth': st.randint(3, 17),\n",
    "            'l2_leaf_reg': st.randint(0, 100),\n",
    "            'rsm': st.uniform(0.0, 1.0),\n",
    "            'random_strength': st.uniform(0.05, 10),\n",
    "            'iterations': st.randint(3, 50),\n",
    "        }\n",
    "    else:\n",
    "        print('Błąd: {} klasyfikator nie jest obsługiwany.'.format(type(clf)))\n",
    "    \n",
    "    # run randomized search\n",
    "    n_iter_search = 10\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=params,\n",
    "                                       n_iter=n_iter_search, cv=5,\n",
    "                                       return_train_score=True, random_state=111)\n",
    "\n",
    "    start = time()\n",
    "    random_search.fit(X, y)\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "          \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    report(random_search.cv_results_)\n",
    "\n",
    "def get_scores():\n",
    "    pass\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "clf1 = XGBClassifier()\n",
    "clf2 = CatBoostClassifier(loss_function='MultiClass', eval_metric='Accuracy', verbose=False)\n",
    "\n",
    "find_params(clf2, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-krotna walidacja krzyżowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, K, clf):\n",
    "    n = np.shape(X)[0]\n",
    "    K_cv_ind = np.random.permutation(n)\n",
    "    for k in range(K):\n",
    "        print('\\nk = ', k)\n",
    "        ind_test = K_cv_ind[round(k * (1 / K) * n): round((k+1) * (1 / K) * n)]\n",
    "        #print('test:', ind_test)\n",
    "        X_test = X[ind_test, :]\n",
    "        y_test = y[ind_test]\n",
    "        if k != 0:\n",
    "            ind_train = K_cv_ind[np.concatenate((np.arange(round(k * (1 / K) * n)),\n",
    "                                                 np.arange(round((k+1) * (1 / K) * n), n)), axis=None)]\n",
    "            X_train = X[ind_train, :]\n",
    "            y_train = y[ind_train]\n",
    "        else:\n",
    "            ind_train = K_cv_ind[range(round((k+1) * (1 / K) * n), n)]\n",
    "            X_train = X[ind_train, :]\n",
    "            y_train = y[ind_train]\n",
    "        #print('train:', ind_train)\n",
    "\n",
    "        max_train = np.amax(X_train, axis=0)\n",
    "        min_train = np.amin(X_train, axis=0)\n",
    "        X_train = 2 * (X_train - min_train) / (max_train - min_train) - 1\n",
    "        X_test = 2 * (X_test - min_train) / (max_train - min_train) - 1\n",
    "\n",
    "        find_params(clf, X_train, y_train)\n",
    "        #params = find_params(clf, X_train, y_train)\n",
    "        #values = predict(X_test, y_test)\n",
    "        \n",
    "cross_validation(X, y, 5, clf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8QAWNjizy_3O"
   },
   "source": [
    "## Open In Colab Badge\n",
    "\n",
    "Anybody can open a copy of any github-hosted notebook within Colab. To make it easier to give people access to live views of GitHub-hosted notebooks,\n",
    "colab provides a [shields.io](http://shields.io/)-style badge, which appears as follows:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
    "\n",
    "The markdown for the above badge is the following:\n",
    "\n",
    "```markdown\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
    "```\n",
    "\n",
    "The HTML equivalent is:\n",
    "\n",
    "```HTML\n",
    "<a href=\"https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "```\n",
    "\n",
    "Remember to replace the notebook URL in this template with the notebook you want to link to."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colab-github-demo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
