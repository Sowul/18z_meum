{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metody ewolucyjne i uczenie się maszyn\n",
    "## Na kilku zadaniach klasyfikacji z repozytorium UCI porównać metody xgboost i catboost\n",
    "### Agnieszka Czaplicka, Bartosz Sowul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test: instalacja potrzebnych modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.12.1.1)\n",
      "Requirement already satisfied: six in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from catboost) (1.11.0)\n",
      "Requirement already satisfied: pandas>=0.19.1 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from catboost) (1.13.3)\n",
      "Requirement already satisfied: enum34 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from catboost) (1.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas>=0.19.1->catboost) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas>=0.19.1->catboost) (2018.9)\n",
      "Requirement already satisfied: xgboost in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.81)\n",
      "Requirement already satisfied: scipy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from xgboost) (1.2.0)\n",
      "Requirement already satisfied: numpy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from xgboost) (1.13.3)\n",
      "Requirement already satisfied: matplotlib in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (1.13.3)\n",
      "Requirement already satisfied: six>=1.10 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (2.7.5)\n",
      "Requirement already satisfied: pytz in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (2018.9)\n",
      "Requirement already satisfied: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (2.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pandas in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from pandas) (1.13.3)\n",
      "Requirement already satisfied: six>=1.5 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from python-dateutil>=2->pandas) (1.11.0)\n",
      "Requirement already satisfied: numpy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (1.13.3)\n",
      "Requirement already satisfied: scikit_learn in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.19.1)\n",
      "Requirement already satisfied: hyperopt in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (0.1.1)\n",
      "Requirement already satisfied: six in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from hyperopt) (1.11.0)\n",
      "Requirement already satisfied: numpy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from hyperopt) (1.13.3)\n",
      "Requirement already satisfied: future in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from hyperopt) (0.17.1)\n",
      "Requirement already satisfied: scipy in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from hyperopt) (1.2.0)\n",
      "Requirement already satisfied: networkx in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from hyperopt) (2.2)\n",
      "Requirement already satisfied: pymongo in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from hyperopt) (3.7.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /media/bs/data/projects/0_moje_portfolio/eiti/eiti/lib/python3.6/site-packages (from networkx->hyperopt) (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "!pip install xgboost\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit_learn\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ładowanie potrzebnych modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-pVhOfzLx9us"
   },
   "source": [
    "## Ładowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44444444,  0.        ,  0.        ,  0.        ,  0.11111111,\n",
       "         0.1       ,  0.22222222,  0.        ,  0.        ],\n",
       "       [ 0.44444444,  0.33333333,  0.33333333,  0.44444444,  0.66666667,\n",
       "         1.        ,  0.22222222,  0.11111111,  0.        ],\n",
       "       [ 0.22222222,  0.        ,  0.        ,  0.        ,  0.11111111,\n",
       "         0.2       ,  0.22222222,  0.        ,  0.        ],\n",
       "       [ 0.55555556,  0.77777778,  0.77777778,  0.        ,  0.22222222,\n",
       "         0.4       ,  0.22222222,  0.66666667,  0.        ],\n",
       "       [ 0.33333333,  0.        ,  0.        ,  0.22222222,  0.11111111,\n",
       "         0.1       ,  0.22222222,  0.        ,  0.        ],\n",
       "       [ 0.77777778,  1.        ,  1.        ,  0.77777778,  0.66666667,\n",
       "         1.        ,  0.88888889,  0.66666667,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.11111111,\n",
       "         1.        ,  0.22222222,  0.        ,  0.        ],\n",
       "       [ 0.11111111,  0.        ,  0.11111111,  0.        ,  0.11111111,\n",
       "         0.1       ,  0.22222222,  0.        ,  0.        ],\n",
       "       [ 0.11111111,  0.        ,  0.        ,  0.        ,  0.11111111,\n",
       "         0.1       ,  0.        ,  0.        ,  0.44444444],\n",
       "       [ 0.33333333,  0.11111111,  0.        ,  0.        ,  0.11111111,\n",
       "         0.1       ,  0.11111111,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# przyklad na zbiorze breast\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "def prepare(filename):\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    df = df.replace('?', np.NaN)\n",
    "    df[[6]] = df[[6]].fillna(value=0)\n",
    "\n",
    "    array = df.values\n",
    "    X = array[:,1:10]\n",
    "    y = np.array([1 if elem == 2 else 0 for elem in df[10]])\n",
    "\n",
    "    imputer = Imputer()\n",
    "    X = imputer.fit_transform(X)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    return X, y\n",
    "\n",
    "X, y = prepare('./data/breast/breast-cancer-wisconsin.data.txt')\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optymalizacja hiperparametrów przy użyciu RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (wykorzystano kod z dokumentacji scikit-learna, dostępny pod adresem https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okok\n",
      "RandomizedSearchCV took 166.20 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.923 (std: 0.023)\n",
      "Parameters: {'depth': 8, 'iterations': 46, 'l2_leaf_reg': 12, 'learning_rate': 0.98255735933865884, 'random_strength': 1.3312444792935674, 'rsm': 0.99904051532414473}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.903 (std: 0.036)\n",
      "Parameters: {'depth': 10, 'iterations': 29, 'l2_leaf_reg': 25, 'learning_rate': 0.49789352617590515, 'random_strength': 9.1359550309309565, 'rsm': 0.2936141483736795}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.899 (std: 0.026)\n",
      "Parameters: {'depth': 12, 'iterations': 21, 'l2_leaf_reg': 15, 'learning_rate': 0.71063573023800297, 'random_strength': 3.0349529475304466, 'rsm': 0.44613450608610605}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#accuracy, F1 score i logloss\n",
    "from time import time\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "import scipy.stats as st\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def find_params(clf, X=None, y=None):\n",
    "    # Utility function to report best scores\n",
    "    def report(results, n_top=3):\n",
    "        for i in range(1, n_top + 1):\n",
    "            candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "            for candidate in candidates:\n",
    "                print(\"Model with rank: {0}\".format(i))\n",
    "                print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                      results['mean_test_score'][candidate],\n",
    "                      results['std_test_score'][candidate]))\n",
    "                print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "                print(\"\")\n",
    "\n",
    "    params = None\n",
    "    if type(clf) == XGBClassifier:\n",
    "        print('ok')\n",
    "#learning_rate\n",
    "#gamma\n",
    "#max_depth\n",
    "#min_child_weight\n",
    "#subsample\n",
    "#colsample_bytree\n",
    "#reg_alpha\n",
    "#reg_lambda\n",
    "#n_estimators\n",
    "        params = {\n",
    "            'learning_rate': st.uniform(0.05, 1.0),\n",
    "            'gamma': st.uniform(0, 10),\n",
    "            'max_depth': st.randint(3, 17),\n",
    "            'min_child_weight': st.expon(0, 50),\n",
    "            'subsample': st.beta(10, 1),\n",
    "            'colsample_bytree': st.beta(10, 1) ,\n",
    "            'reg_alpha': st.expon(0, 50),\n",
    "            'reg_lambda': st.randint(0, 100),\n",
    "            'n_estimators': st.randint(3, 50),\n",
    "        }\n",
    "    elif type(clf) == CatBoostClassifier:\n",
    "#learning_rate\n",
    "#depth\n",
    "#l2_leaf_reg\n",
    "#rsm\n",
    "#random_strength\n",
    "#iterations\n",
    "        print('okok')\n",
    "        params = {\n",
    "            'learning_rate': st.uniform(0.05, 1.0),\n",
    "            'depth': st.randint(3, 17),\n",
    "            'l2_leaf_reg': st.randint(0, 100),\n",
    "            'rsm': st.uniform(0.0, 1.0),\n",
    "            'random_strength': st.uniform(0.05, 10),\n",
    "            'iterations': st.randint(3, 50),\n",
    "        }\n",
    "    else:\n",
    "        print('Błąd: {} klasyfikator nie jest obsługiwany.'.format(type(clf)))\n",
    "    \n",
    "    # run randomized search\n",
    "    n_iter_search = 10\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=params,\n",
    "                                       n_iter=n_iter_search, cv=5,\n",
    "                                       return_train_score=True, random_state=111)\n",
    "\n",
    "    start = time()\n",
    "    random_search.fit(X, y)\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "          \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    report(random_search.cv_results_)\n",
    "\n",
    "def get_scores():\n",
    "    pass\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "clf1 = XGBClassifier()\n",
    "clf2 = CatBoostClassifier(loss_function='MultiClass', eval_metric='Accuracy', verbose=False)\n",
    "\n",
    "find_params(clf2, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8QAWNjizy_3O"
   },
   "source": [
    "## Open In Colab Badge\n",
    "\n",
    "Anybody can open a copy of any github-hosted notebook within Colab. To make it easier to give people access to live views of GitHub-hosted notebooks,\n",
    "colab provides a [shields.io](http://shields.io/)-style badge, which appears as follows:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
    "\n",
    "The markdown for the above badge is the following:\n",
    "\n",
    "```markdown\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
    "```\n",
    "\n",
    "The HTML equivalent is:\n",
    "\n",
    "```HTML\n",
    "<a href=\"https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "```\n",
    "\n",
    "Remember to replace the notebook URL in this template with the notebook you want to link to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ładowanie i przygotowanie zbiorów danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# zbiory Adult/Annealing/Breast\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "\n",
    "\n",
    "def prepare(filename):\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    # df = df.replace('?', np.NaN)\n",
    "    # df = df.fillna(value=0)\n",
    "    # print(df.select_dtypes(exclude=['int', np.float]))\n",
    "    if filename[-32:] == 'breast-cancer-wisconsin.data.txt':\n",
    "        df[6] = df[6].replace('?', 0)\n",
    "        df[6] = df[6].astype('int', errors='ignore')\n",
    "        df[6] = df[6].replace(0, np.median(df[6]))\n",
    "    #print(df.dtypes)\n",
    "\n",
    "    array = df.values\n",
    "    X = array[:, 0:df.shape[1]-1]\n",
    "\n",
    "    for i in range(np.shape(X)[1]):\n",
    "        if df[i].dtype == object:\n",
    "            names_in_col = df[i].unique()\n",
    "            names_in_col = sorted(names_in_col, key=lambda v: (v.lower(), v))\n",
    "            if names_in_col[0].strip() == '?':\n",
    "                names_in_col = names_in_col[1:]\n",
    "            elif names_in_col[len(names_in_col) - 1].strip() == '?':\n",
    "                names_in_col = names_in_col[:-1]\n",
    "            print(names_in_col)\n",
    "            col_dict = dict(zip(names_in_col, range(1, len(names_in_col)+1)))\n",
    "            X[:, i] = np.array([col_dict.get(elem, np.NaN) for elem in df[i]])\n",
    "        else:\n",
    "            df[i] = df[i].replace('?', np.NaN)\n",
    "            # df[i] = df[i].fillna(value=0)\n",
    "            X[:, i] = np.array(df[i])\n",
    "\n",
    "    if df[df.shape[1]-1].dtype == object:\n",
    "        names_in_col = df[df.shape[1]-1].unique()\n",
    "        names_in_col = sorted(names_in_col, key=lambda v: (v.lower(), v))\n",
    "        print(names_in_col)\n",
    "        col_dict = dict(zip(names_in_col, range(len(names_in_col))))\n",
    "        y = np.array([col_dict.get(elem) for elem in df[df.shape[1]-1]])\n",
    "    else:\n",
    "        y = array[:, df.shape[1]-1]\n",
    "\n",
    "    imputer = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "    X = imputer.fit_transform(X)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    return X, y\n",
    "\n",
    "print(\"Adult\")\n",
    "X, y = prepare('./data/adult/adult.data.txt')\n",
    "print(\"\\n------------------------------------------------\\n\\nAnnealing\")\n",
    "X2, y2 = prepare('./data/annealing/anneal.data.txt')\n",
    "X2 = X2[:, np.concatenate((np.arange(5), [8, 26, 27, 28, 29, 31]), axis=None)]\n",
    "print(\"\\n------------------------------------------------\\n\\nBreast\")\n",
    "X3, y3 = prepare('./data/breast/breast-cancer-wisconsin.data.txt')\n",
    "X3 = X3[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colab-github-demo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
